{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image, ImageOps\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = glob.glob(\"../../data/globular_dataset_ds9/train/images/*\")\n",
    "# path_train_labels = glob.glob(\"../../data/globular_dataset_ds9/train/labels/*\")\n",
    "# path_test = glob.glob(\"../../data/globular_dataset_ds9/test/images/*\")\n",
    "# path_test_labels = glob.glob(\"../../data/globular_dataset_ds9/test/labels/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, gray_mode = False, normalize = False):\n",
    "  images_list = []\n",
    "  images_name = []\n",
    "  labels_list = []\n",
    "  for i in path:\n",
    "    if gray_mode:\n",
    "      image = cv2.imread(i, 0)\n",
    "    else:\n",
    "      image = cv2.imread(i, 1)\n",
    "\n",
    "    if normalize:\n",
    "      # normalize the image to 0-1\n",
    "      image = image / 255.0\n",
    "    else:\n",
    "      pass\n",
    "\n",
    "    # save as a numpy array in the list\n",
    "    images_list.append(image)\n",
    "    # save the name of the image\n",
    "    images_name.append(os.path.basename(i))\n",
    "    # save the label of the image\n",
    "    labels_list.append(os.path.basename(i).split(\"_\")[0])\n",
    "  return np.array(images_list), np.array(images_name), np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_train, images_train_name, labels_train = load_data(path_train, gray_mode = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.array([np.array(ImageOps.grayscale(Image.open(fname))) for fname in path_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "data_train = data_train / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 1024, 1024, 1)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 1024, 1024, 4)     40        \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1024, 1024, 8)     296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 512, 512, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 512, 512, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 512, 512, 32)      4640      \n",
      "_________________________________________________________________\n",
      "encoder (MaxPooling2D)       (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 512, 512, 16)      4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 1024, 1024, 8)     1160      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 1024, 1024, 4)     292       \n",
      "_________________________________________________________________\n",
      "decoder (Conv2D)             (None, 1024, 1024, 1)     37        \n",
      "=================================================================\n",
      "Total params: 12,257\n",
      "Trainable params: 12,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build cnn autoencoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "w = data_train[0].shape[0]\n",
    "h = data_train[0].shape[1]\n",
    "channel = 1\n",
    "input_img = Input(shape=(w, h, channel))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(4, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "encoder = layers.MaxPooling2D((2, 2), padding=\"same\", name='encoder')(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(16, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(encoder) # model should learn what is the best upsampling for the job from transposed convolutions\n",
    "x = layers.Conv2DTranspose(8, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x) # upsampling using transposed convolutions\n",
    "x = layers.Conv2DTranspose(4, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "decoder = layers.Conv2D(channel, (3, 3), activation=\"sigmoid\", padding=\"same\", name='decoder')(x)\n",
    "\n",
    "\n",
    "autoencoder = Model(input_img, decoder)\n",
    "opt = tf.optimizers.Adam(learning_rate=0.01)\n",
    "autoencoder.compile(optimizer=opt, loss='MeanSquaredError')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 49s 253ms/step - loss: 0.0556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19e4b7f6d08>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(\n",
    "    x=data_train,\n",
    "    y=data_train,\n",
    "    epochs=1,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = data_train[0].reshape(1, w, h, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024, 1024, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 37 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000019E4BB225E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# predict the images by encoder\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoder').output)\n",
    "encoder_output = encoder.predict(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaxPooling2D' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19400\\2602076143.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# predict encoder_output by decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decoder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MaxPooling2D' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "# predict encoder_output by decoder\n",
    "decoder = Model(inputs=autoencoder.get_layer('encoder').inputs, outputs=autoencoder.get_layer('decoder').output)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(decoder_output.reshape(1024, 1024, 1), cmap='gray') \n",
    "plt.show()  # display it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
